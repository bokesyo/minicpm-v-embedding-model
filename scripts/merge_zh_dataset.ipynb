{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset information\n",
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simclue ##\n",
    "\n",
    "from datasets import load_dataset\n",
    "import jsonlines\n",
    "\n",
    "###### ATTENTION: NEG and INSTRUCTION need edit!!!! #######\n",
    "\n",
    "# QUERY_INSTRUCTION = \"Represent the sentence for retrieving duplicate sentences;\"\n",
    "# DOC_INSTRUCTION = \"Represent the sentence for retrieving duplicate sentences;\"\n",
    "QUERY_INSTRUCTION = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "DOC_INSTRUCTION = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "# read simclue\n",
    "simclue_path = \"../../dataset/simclue_public/train_rank.json\"\n",
    "simclue_output_path = \"../../dataset/our-zh/simclue.jsonl\"\n",
    "simclue_data = []\n",
    "\n",
    "with jsonlines.open(simclue_path) as reader:\n",
    "    for obj in reader:\n",
    "        simclue_data.append(obj)\n",
    "    \n",
    "keys_to_keep = [\"query\", \"neg\", \"pos\"]\n",
    "keys_to_delete = [key for key in simclue_data[0].keys() if key not in keys_to_keep]\n",
    "\n",
    "# add instruction\n",
    "for item in simclue_data:\n",
    "    item[\"pos\"] = item[\"title\"]\n",
    "    item[\"neg\"] = item[\"neg_title\"]\n",
    "    item[\"query\"] = [QUERY_INSTRUCTION,item[\"query\"]]\n",
    "    item[\"neg\"] = [DOC_INSTRUCTION,item[\"neg\"]]\n",
    "    item[\"pos\"] = [DOC_INSTRUCTION,item[\"pos\"]]\n",
    "    for key in keys_to_delete:\n",
    "        item.pop(key)\n",
    "        \n",
    "with jsonlines.open(simclue_output_path, mode='w') as writer:\n",
    "    writer.write_all(simclue_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TOKENIZERS_PARALLELISM=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from string import Template\n",
    "from FlagEmbedding import FlagModel\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "# from joblib import Parallel, delayed\n",
    "import faiss\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "###### ATTENTION: NEG and INSTRUCTION need edit!!!! #######\n",
    "\n",
    "QUERY_INSTRUCTION = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "DOC_INSTRUCTION = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "\n",
    "QUERY_INSTRUCTION_FOR_EMBEDMODEL = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "\n",
    "dataset_names = [\n",
    "    \"alpaca_gpt4\",\n",
    "    \"belle_2m\",\n",
    "    \"chatmed_consult\",\n",
    "    \"csl\",\n",
    "    \"dureader_robust\",\n",
    "    \"firefly\",\n",
    "    \"miracl\",\n",
    "    \"mlqa\",\n",
    "    \"webqa\",\n",
    "    \"xlsum\",\n",
    "    \"zhihu_kol\"\n",
    "]\n",
    "dataset_paths_template = Template(\"../../dataset/m3e/$dataset_name.dataset\")\n",
    "dataset_output_paths_template = Template(\"../../dataset/our-zh/$dataset_name.jsonl\")\n",
    "\n",
    "model = FlagModel('BAAI/bge-base-zh-v1.5', \n",
    "                  query_instruction_for_retrieval=\"为这个句子生成表示以用于检索相关文章：\",\n",
    "                  use_fp16=True) \n",
    "keys_to_keep = [\"query\", \"pos\"]\n",
    "\n",
    "dataset_spilt = {\n",
    "    \"csl\":\"csl\",\n",
    "}\n",
    "\n",
    "\n",
    "for d in dataset_names:\n",
    "    print(\"================{}==============\".format(d))\n",
    "    # if os.path.exists(dataset_output_paths_template.substitute(dataset_name=d)):\n",
    "    #     continue\n",
    "    dataset_path = dataset_paths_template.substitute(dataset_name=d)\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    dataset = dataset[\"train\"]\n",
    "    print(\"length:\",len(dataset))\n",
    "    # cut only 100\n",
    "    # dataset = dataset[dataset_spilt.get(d,\"train\")]\n",
    "    dataset = dataset.rename_columns({\"text\" : \"query\", \"text_pos\" : \"pos\"})\n",
    "    # dataset = dataset.add_column(\"neg\",[\"\"]*len(dataset))\n",
    "    keys_to_delete = [k for k in dataset.column_names if k not in keys_to_keep]\n",
    "    dataset = dataset.remove_columns(keys_to_delete)\n",
    "    \n",
    "    # find the hard negative sample from the dataset\n",
    "    queries = [x[\"query\"] for x in dataset]#[:100]\n",
    "    docs = [x[\"pos\"] for x in dataset]#[:100]\n",
    "    q_embeddings = model.encode_queries(queries)\n",
    "    d_embeddings = model.encode(docs)\n",
    "    # for each query, find the hard negative sample from 25-35\n",
    "    # use numpy to find the hard negative sample\n",
    "    # parrallel \n",
    "    negs = [None] * len(dataset)\n",
    "    # def process_query(i):\n",
    "    #     similarity_q = np.dot(q_embeddings[i], d_embeddings.T)\n",
    "    #     negs[i] = docs[np.argsort(similarity_q)[::-1][np.random.randint(25, 36)]]\n",
    "    #     # print(dataset[i])\n",
    "    #     return\n",
    "    \n",
    "    # # for i in range(len(dataset)):\n",
    "    # Parallel(n_jobs=-1,backend='threading')(delayed(process_query)(i) for i in tqdm(range(len(dataset))))\n",
    "    # print(negs)\n",
    "    \n",
    "    # use Faiss gpu\n",
    "    # Step 1: change data type\n",
    "    \n",
    "    q_embeddings = q_embeddings.astype(\"float32\")\n",
    "    d_embeddings = d_embeddings.astype(\"float32\")\n",
    "    \n",
    "    # Step 2 : Instantiate a FAISS index\n",
    "    dim = q_embeddings.shape[1]\n",
    "    measure = faiss.METRIC_INNER_PRODUCT\n",
    "    param = 'IVF{},PQ16'.format(len(dataset)//100)\n",
    "    index = faiss.index_factory(dim, param, measure)\n",
    "    index.train(d_embeddings)\n",
    "    index.add(d_embeddings)\n",
    "    print(\"index\")\n",
    "    \n",
    "    # Step 5: Search the index\n",
    "    index.nprobe = 10\n",
    "    _,similarity_q_index = index.search(q_embeddings, 36)\n",
    "    negs_index = np.random.randint(25, 36, size=(d_embeddings.shape[0],))\n",
    "    negs = [docs[similarity_q_index[i][negs_index[i]]] for i in range(len(dataset))]\n",
    "    # negs = [docs[negs_index[i]] for i in range(len(dataset))]\n",
    "    # negs = [docs[np.argsort(similarity_q[i])[::-1][np.random.randint(25, 36)]] for i in range(len(dataset))]\n",
    "    \n",
    "    \n",
    "    \n",
    "    dataset = dataset.add_column(\"neg\",negs)\n",
    "    dataset = dataset.map(lambda x: {\"query\" : [QUERY_INSTRUCTION, x[\"query\"]], \"pos\" : [DOC_INSTRUCTION, x[\"pos\"]], \"neg\" : [DOC_INSTRUCTION, x[\"neg\"]]})\n",
    "    with jsonlines.open(dataset_output_paths_template.substitute(dataset_name=d), mode=\"w\") as f:\n",
    "        for x in dataset:#[:100]:\n",
    "            f.write(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import jsonlines\n",
    "output_file = \"../../dataset/our-zh/marco_chinese.jsonl\"\n",
    "dataset = load_dataset('unicamp-dl/mmarco', 'chinese',trust_remote_code=True)\n",
    "dataset = dataset['train']\n",
    "QUERY_INSTRUCTION = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "DOC_INSTRUCTION = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "dataset = dataset.rename_columns({\"query\" : \"query\", \"pos\" : \"positive\",\"neg\":\"negative\"})\n",
    "dataset = dataset.map(lambda x: {\"query\" : [QUERY_INSTRUCTION, x[\"query\"]], \"pos\" : [DOC_INSTRUCTION, x[\"positive\"]], \"neg\" : [DOC_INSTRUCTION, x[\"negative\"]]})\n",
    "with jsonlines.open(output_file, mode='w') as writer:\n",
    "    for data in dataset:\n",
    "        writer.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10w_why 161023\n",
      "NCPPolicies 3366\n",
      "alpaca_gpt4 43894\n",
      "cMedQA2 99483\n",
      "chatmed_consult 252536\n",
      "cmrc2018 9157\n",
      "csl 379166\n",
      "csquad 64215\n",
      "dureader_retrieval 79158\n",
      "dureader_robust 14088\n",
      "economic_information_daily_clean 33046\n",
      "marco_chinese 375525\n",
      "mcpr-ecom 84337\n",
      "mcpr-medical 45799\n",
      "mcpr-video 73834\n",
      "mlqa 52290\n",
      "retrieval_data_llm 174659\n",
      "simclue 371088\n",
      "t2ranking 140566\n",
      "webqa 34375\n",
      "whys 33298\n",
      "xlsum 77328\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "datasets_path = \"../../dataset/our-zh/hard_negs/clean\"\n",
    "# for all the files\n",
    "files = os.listdir(datasets_path)\n",
    "files = [file for file in files if file.endswith(\".jsonl\")]\n",
    "\n",
    "# in_domain_datasets = [\n",
    "#     'cMedQA2',\n",
    "#     'dureader_retrieval',\n",
    "#     'marco_chinese',\n",
    "#     'mcpr-ecom',\n",
    "#     'mcpr-medical',\n",
    "#     'mcpr-video',\n",
    "#     'NCPPolicies',\n",
    "#     't2ranking'\n",
    "#     ]\n",
    "# # # files\n",
    "# files = ['clean'+file+'.jsonl' for file in in_domain_datasets]\n",
    "data = []\n",
    "\n",
    "for file_index,file in enumerate(files):\n",
    "    if file.startswith(\"train\"):\n",
    "        continue\n",
    "    if file.startswith(\"shenqing\"):\n",
    "        continue\n",
    "    if file.startswith(\"zhihu\"):\n",
    "        continue\n",
    "    line_count = sum(1 for line in open(os.path.join(datasets_path, file), 'r'))\n",
    "    print(file[:-6],line_count)\n",
    "    with jsonlines.open(os.path.join(datasets_path, file)) as reader:\n",
    "        i = 0\n",
    "        for obj in reader:\n",
    "            obj[\"task_id\"] = file_index\n",
    "            if len(obj[\"neg\"]) < 6:\n",
    "                print(len(obj[\"neg\"]))\n",
    "            # obj[\"neg\"] = obj[\"neg\"][:6]\n",
    "            # print(len(obj[\"neg\"][:6])) n\n",
    "            data.append(obj)\n",
    "            i += 1\n",
    "            # if i > 500000:\n",
    "            #     break\n",
    "\n",
    "output_path = \"../../dataset/our-zh/train.jsonl\"\n",
    "with jsonlines.open(output_path, mode=\"w\") as writer:\n",
    "    writer.write_all(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "datasets_path = \"../../dataset/our-zh/hard_negs/retrieval_data_llm.jsonl\"\n",
    "with jsonlines.open(datasets_path ) as reader:\n",
    "    dataset = list(reader)\n",
    "    \n",
    "for obj in dataset:\n",
    "    obj[\"neg\"] = obj[\"neg\"][:11]\n",
    "    \n",
    "with jsonlines.open(datasets_path , mode=\"w\") as writer:\n",
    "    writer.write_all(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 0\n",
      "10001 0\n",
      "10002 0\n",
      "10003 2347\n",
      "10004 0\n",
      "10005 0\n",
      "10006 0\n",
      "10007 0\n",
      "10008 0\n",
      "10009 0\n",
      "10010 143\n",
      "10011 0\n",
      "10012 349\n",
      "10013 0\n",
      "10014 4\n",
      "10015 6426\n",
      "10016 10\n",
      "10017 165\n",
      "10018 0\n",
      "10019 0\n",
      "10020 21\n",
      "10021 151\n",
      "10022 3\n",
      "10023 682\n",
      "10024 127\n",
      "10025 0\n",
      "10026 1343\n",
      "10027 128646\n",
      "10028 0\n",
      "10029 0\n",
      "10030 0\n",
      "10031 0\n",
      "10032 5655\n",
      "10033 1784\n",
      "10034 4426\n",
      "10035 234\n",
      "10036 1795\n",
      "10037 0\n",
      "10038 57\n",
      "10039 5496\n",
      "10040 255\n",
      "10041 0\n",
      "10042 44789\n",
      "10043 2054\n",
      "10044 0\n",
      "10045 0\n",
      "10046 1874\n",
      "10047 95\n",
      "10048 0\n",
      "10049 0\n",
      "10050 592\n",
      "10051 0\n",
      "10052 51\n",
      "10053 2\n",
      "10054 0\n",
      "10055 0\n",
      "10056 473\n",
      "10057 0\n",
      "10058 408\n",
      "10059 113\n",
      "10060 389012\n",
      "10061 0\n",
      "10062 175409\n",
      "10063 0\n",
      "10064 0\n",
      "10065 0\n",
      "10066 0\n",
      "10067 123\n",
      "10068 170298\n",
      "10069 0\n",
      "10070 0\n",
      "10071 64\n",
      "10072 0\n",
      "10073 0\n",
      "10074 0\n",
      "10075 0\n",
      "10076 2853\n",
      "10077 753\n",
      "10078 0\n",
      "10079 0\n",
      "10080 0\n",
      "10081 85\n",
      "10082 98\n",
      "10083 0\n",
      "10084 0\n",
      "10085 0\n",
      "10086 2879\n",
      "10087 291\n",
      "10088 881\n",
      "10089 0\n",
      "10090 227\n",
      "10091 0\n",
      "10092 0\n",
      "10093 129\n",
      "10094 0\n",
      "10095 334\n",
      "10096 0\n",
      "10097 0\n",
      "10098 24\n",
      "10099 0\n",
      "10100 0\n",
      "10101 0\n",
      "10102 620\n",
      "10103 380\n",
      "10104 0\n",
      "10105 0\n",
      "10106 18\n",
      "10107 0\n",
      "10108 0\n",
      "10109 3716\n",
      "10110 159\n",
      "10111 0\n",
      "10112 533\n",
      "10113 17\n",
      "10114 1083\n",
      "10115 18\n",
      "10116 0\n",
      "10117 0\n",
      "10118 155695\n",
      "10119 0\n",
      "10120 0\n",
      "10121 303\n",
      "10122 1262\n",
      "10123 0\n",
      "10124 0\n",
      "10125 0\n",
      "10126 0\n",
      "10127 0\n",
      "10128 796\n",
      "10129 500\n",
      "10130 2642\n",
      "10131 0\n",
      "10132 0\n",
      "10133 1323\n",
      "10134 0\n",
      "10135 1\n",
      "10136 849\n",
      "10137 24\n",
      "10138 810\n",
      "10139 2731\n",
      "10140 0\n",
      "10141 386\n",
      "10142 4956\n",
      "10143 95\n",
      "10144 5525\n",
      "10145 1685\n",
      "10146 1474\n",
      "10147 0\n",
      "10148 347\n",
      "10149 0\n",
      "10150 14968\n",
      "10151 0\n",
      "10152 138471\n",
      "10153 689\n",
      "10154 143251\n",
      "10155 0\n",
      "10156 0\n",
      "10157 3108\n",
      "10158 0\n",
      "10159 12943\n",
      "10160 166\n",
      "10161 5\n",
      "10162 389\n",
      "10163 0\n",
      "10164 0\n",
      "10165 183\n",
      "10166 130\n",
      "10167 143\n",
      "10168 0\n",
      "10169 5489\n",
      "10170 0\n",
      "10171 83\n",
      "10172 0\n",
      "10173 946\n",
      "10174 0\n",
      "10175 496\n",
      "10176 0\n",
      "10177 29\n",
      "10178 4407\n",
      "10179 1506\n",
      "10180 375\n",
      "10181 592\n",
      "10182 1\n",
      "10183 888\n",
      "10184 0\n",
      "10185 0\n",
      "10186 0\n",
      "10187 0\n",
      "10188 38\n",
      "10189 34\n",
      "10190 0\n",
      "10191 5962\n",
      "10192 0\n",
      "10193 47033\n",
      "10194 146\n",
      "10195 0\n",
      "10196 68\n",
      "10197 226\n",
      "10198 3967\n",
      "10199 2684\n",
      "10200 0\n",
      "10201 0\n",
      "10202 1\n",
      "10203 0\n",
      "10204 0\n",
      "10205 0\n",
      "10206 5175\n",
      "10207 737\n",
      "10208 118\n",
      "10209 194\n",
      "10210 1\n",
      "10211 44\n",
      "10212 0\n",
      "10213 0\n",
      "10214 0\n",
      "10215 57381\n",
      "10216 0\n",
      "10217 0\n",
      "10218 0\n",
      "10219 1891\n",
      "10220 0\n",
      "10221 0\n",
      "10222 0\n",
      "10223 0\n",
      "10224 0\n",
      "10225 0\n",
      "10226 489\n",
      "10227 0\n",
      "10228 0\n",
      "10229 0\n",
      "10230 2956\n",
      "10231 0\n",
      "10232 0\n",
      "10233 2132\n",
      "10234 0\n",
      "10235 0\n",
      "10236 304\n",
      "10237 0\n",
      "10238 0\n",
      "10239 906\n",
      "10240 0\n",
      "10241 0\n",
      "10242 0\n",
      "10243 1535\n",
      "10244 0\n",
      "10245 321\n",
      "10246 835\n",
      "10247 1526\n",
      "10248 96\n",
      "10249 0\n",
      "10250 943\n",
      "10251 3102\n",
      "10252 378\n",
      "10253 5225\n",
      "10254 0\n",
      "10255 671\n",
      "10256 22743\n",
      "10257 0\n",
      "10258 0\n",
      "10259 0\n",
      "10260 91\n",
      "10261 65\n",
      "10262 6\n",
      "10263 189\n",
      "10264 108730\n",
      "10265 0\n",
      "10266 0\n",
      "10267 2110\n",
      "10268 0\n",
      "10269 0\n",
      "10270 0\n",
      "10271 0\n",
      "10272 0\n",
      "10273 0\n",
      "10274 3916\n",
      "10275 0\n",
      "10276 793\n",
      "10277 2\n",
      "10278 190773\n",
      "10279 0\n",
      "10280 0\n",
      "10281 997\n",
      "10282 170\n",
      "10283 0\n",
      "10284 361\n",
      "10285 0\n",
      "10286 0\n",
      "10287 1647\n",
      "10288 0\n",
      "10289 1246\n",
      "10290 25\n",
      "10291 0\n",
      "10292 0\n",
      "10293 466\n",
      "10294 863\n",
      "10295 2951\n",
      "10296 0\n",
      "10297 0\n",
      "10298 879\n",
      "10299 1988\n",
      "10300 1720\n",
      "10301 2896\n",
      "10302 0\n",
      "10303 0\n",
      "10304 0\n",
      "10305 113\n",
      "10306 782\n",
      "10307 254\n",
      "10308 0\n",
      "10309 0\n",
      "10310 0\n",
      "10311 17\n",
      "10312 135654\n",
      "10313 0\n",
      "10314 0\n",
      "10315 0\n",
      "10316 4737\n",
      "10317 0\n",
      "10318 0\n",
      "10319 194\n",
      "10320 426\n",
      "10321 0\n",
      "10322 0\n",
      "10323 44\n",
      "10324 0\n",
      "10325 0\n",
      "10326 581\n",
      "10327 0\n",
      "10328 0\n",
      "10329 0\n",
      "10330 0\n",
      "10331 0\n",
      "10332 547\n",
      "10333 56\n",
      "10334 6\n",
      "10335 2756\n",
      "10336 0\n",
      "10337 0\n",
      "10338 0\n",
      "10339 0\n",
      "10340 0\n",
      "10341 4392\n",
      "10342 0\n",
      "10343 489\n",
      "10344 0\n",
      "10345 0\n",
      "10346 139\n",
      "10347 0\n",
      "10348 196178\n",
      "10349 109\n",
      "10350 2116\n",
      "10351 1879\n",
      "10352 234\n",
      "10353 1\n",
      "10354 2537\n",
      "10355 152\n",
      "10356 1134\n",
      "10357 0\n",
      "10358 98\n",
      "10359 353\n",
      "10360 4991\n",
      "10361 0\n",
      "10362 319\n",
      "10363 0\n",
      "10364 266\n",
      "10365 18\n",
      "10366 0\n",
      "10367 1180\n",
      "10368 0\n",
      "10369 0\n",
      "10370 26\n",
      "10371 0\n",
      "10372 156081\n",
      "10373 2916\n",
      "10374 0\n",
      "10375 32\n",
      "10376 6474\n",
      "10377 3494\n",
      "10378 1668\n",
      "10379 2516\n",
      "10380 1866\n",
      "10381 0\n",
      "10382 8\n",
      "10383 0\n",
      "10384 0\n",
      "10385 115\n",
      "10386 407\n",
      "10387 0\n",
      "10388 0\n",
      "10389 186\n",
      "10390 0\n",
      "10391 0\n",
      "10392 0\n",
      "10393 1410\n",
      "10394 3080\n",
      "10395 330\n",
      "10396 0\n",
      "10397 211\n",
      "10398 0\n",
      "10399 0\n",
      "10400 80\n",
      "10401 0\n",
      "10402 0\n",
      "10403 0\n",
      "10404 6077\n",
      "10405 29\n",
      "10406 19\n",
      "10407 0\n",
      "10408 32\n",
      "10409 2780\n",
      "10410 753\n",
      "10411 0\n",
      "10412 485\n",
      "10413 112\n",
      "10414 339\n",
      "10415 2463\n",
      "10416 210\n",
      "10417 0\n",
      "10418 0\n",
      "10419 82236\n",
      "10420 0\n",
      "10421 0\n",
      "10422 0\n",
      "10423 0\n",
      "10424 0\n",
      "10425 0\n",
      "10426 368\n",
      "10427 193596\n",
      "10428 0\n",
      "10429 4743\n",
      "10430 0\n",
      "10431 5294\n",
      "10432 1356\n",
      "10433 0\n",
      "10434 0\n",
      "10435 78\n",
      "10436 0\n",
      "10437 468\n",
      "10438 135488\n",
      "10439 0\n",
      "10440 0\n",
      "10441 1615\n",
      "10442 176\n",
      "10443 0\n",
      "10444 0\n",
      "10445 0\n",
      "10446 1322\n",
      "10447 0\n",
      "10448 0\n",
      "10449 207\n",
      "10450 1605\n",
      "10451 0\n",
      "10452 0\n",
      "10453 4002\n",
      "10454 3012\n",
      "10455 3110\n",
      "10456 0\n",
      "10457 1169\n",
      "10458 2195\n",
      "10459 0\n",
      "10460 0\n",
      "10461 2090\n",
      "10462 0\n",
      "10463 57\n",
      "10464 52\n",
      "10465 0\n",
      "10466 0\n",
      "10467 0\n",
      "10468 0\n",
      "10469 18\n",
      "10470 123\n",
      "10471 673\n",
      "10472 0\n",
      "10473 379\n",
      "10474 0\n",
      "10475 139\n",
      "10476 5387\n",
      "10477 456\n",
      "10478 0\n",
      "10479 8\n",
      "10480 0\n",
      "10481 0\n",
      "10482 0\n",
      "10483 1292\n",
      "10484 35\n",
      "10485 934\n",
      "10486 0\n",
      "10487 0\n",
      "10488 0\n",
      "10489 2677\n",
      "10490 995\n",
      "10491 0\n",
      "10492 5405\n",
      "10493 101919\n",
      "10494 3639\n",
      "10495 0\n",
      "10496 0\n",
      "10497 0\n",
      "10498 296\n",
      "10499 288\n",
      "10500 0\n",
      "10501 224\n",
      "10502 0\n",
      "10503 0\n",
      "10504 0\n",
      "10505 1258\n",
      "10506 0\n",
      "10507 11061\n",
      "10508 4918\n",
      "10509 2011\n",
      "10510 3392\n",
      "10511 0\n",
      "10512 0\n",
      "10513 0\n",
      "10514 0\n",
      "10515 0\n",
      "10516 0\n",
      "10517 0\n",
      "10518 755\n",
      "10519 0\n",
      "10520 3025\n",
      "10521 103685\n",
      "10522 1179\n",
      "10523 0\n",
      "10524 0\n",
      "10525 0\n",
      "10526 1522\n",
      "10527 0\n",
      "10528 0\n",
      "10529 0\n",
      "10530 943\n",
      "10531 0\n",
      "10532 383\n",
      "10533 1093\n",
      "10534 0\n",
      "10535 0\n",
      "10536 0\n",
      "10537 188\n",
      "10538 0\n",
      "10539 0\n",
      "10540 0\n",
      "10541 213\n",
      "10542 691\n",
      "10543 0\n",
      "10544 135\n",
      "10545 0\n",
      "10546 0\n",
      "10547 0\n",
      "10548 3259\n",
      "10549 0\n",
      "10550 42\n",
      "10551 0\n",
      "10552 1107\n",
      "10553 0\n",
      "10554 0\n",
      "10555 158\n",
      "10556 57\n",
      "10557 163\n",
      "10558 0\n",
      "10559 6141\n",
      "10560 257\n",
      "10561 59\n",
      "10562 1\n",
      "10563 497\n",
      "10564 0\n",
      "10565 4945\n",
      "10566 0\n",
      "10567 1\n",
      "10568 0\n",
      "10569 0\n",
      "10570 1020\n",
      "10571 31\n",
      "10572 0\n",
      "10573 0\n",
      "10574 0\n",
      "10575 683\n",
      "10576 39\n",
      "10577 1590\n",
      "10578 153\n",
      "10579 0\n",
      "10580 0\n",
      "10581 11\n",
      "10582 0\n",
      "10583 7\n",
      "10584 0\n",
      "10585 0\n",
      "10586 0\n",
      "10587 0\n",
      "10588 0\n",
      "10589 2220\n",
      "10590 0\n",
      "10591 0\n",
      "10592 487\n",
      "10593 0\n",
      "10594 3\n",
      "10595 0\n",
      "10596 0\n",
      "10597 38\n",
      "10598 521\n",
      "10599 287\n",
      "10600 0\n",
      "10601 0\n",
      "10602 71\n",
      "10603 0\n",
      "10604 0\n",
      "10605 351\n",
      "10606 0\n",
      "10607 785\n",
      "10608 2000\n",
      "10609 0\n",
      "10610 0\n",
      "10611 0\n",
      "10612 3\n",
      "10613 5\n",
      "10614 234\n",
      "10615 464\n",
      "10616 0\n",
      "10617 12\n",
      "10618 0\n",
      "10619 0\n",
      "10620 119\n",
      "10621 0\n",
      "10622 49\n",
      "10623 0\n",
      "10624 4575\n",
      "10625 0\n",
      "10626 11\n",
      "10627 0\n",
      "10628 43\n",
      "10629 5\n",
      "10630 0\n",
      "10631 0\n",
      "10632 0\n",
      "10633 88127\n",
      "10634 223\n",
      "10635 0\n",
      "10636 0\n",
      "10637 238\n",
      "10638 99886\n",
      "10639 106880\n",
      "10640 2377\n",
      "10641 5077\n",
      "10642 0\n",
      "10643 11\n",
      "10644 1\n",
      "10645 54\n",
      "10646 0\n",
      "10647 1371\n",
      "10648 38\n",
      "10649 1551\n",
      "10650 0\n",
      "10651 0\n",
      "10652 5285\n",
      "10653 190\n",
      "10654 108\n",
      "10655 190\n",
      "10656 908\n",
      "10657 950\n",
      "10658 1466\n",
      "10659 0\n",
      "10660 973\n",
      "10661 0\n",
      "10662 0\n",
      "10663 0\n",
      "10664 0\n",
      "10665 0\n",
      "10666 2576\n",
      "10667 204\n",
      "10668 882\n",
      "10669 1\n",
      "10670 1\n",
      "10671 320\n",
      "10672 538\n",
      "10673 907\n",
      "10674 82\n",
      "10675 0\n",
      "10676 0\n",
      "10677 0\n",
      "10678 149971\n",
      "10679 0\n",
      "10680 5837\n",
      "10681 14\n",
      "10682 82\n",
      "10683 0\n",
      "10684 4910\n",
      "10685 0\n",
      "10686 0\n",
      "10687 0\n",
      "10688 49861\n",
      "10689 0\n",
      "10690 0\n",
      "10691 0\n",
      "10692 0\n",
      "10693 0\n",
      "10694 130\n",
      "10695 0\n",
      "10696 0\n",
      "10697 172\n",
      "10698 111738\n",
      "10699 0\n",
      "10700 2\n",
      "10701 6377\n",
      "10702 0\n",
      "10703 0\n",
      "10704 0\n",
      "10705 0\n",
      "10706 0\n",
      "10707 112\n",
      "10708 60\n",
      "10709 324\n",
      "10710 651\n",
      "10711 103\n",
      "10712 367\n",
      "10713 0\n",
      "10714 0\n",
      "10715 487\n",
      "10716 0\n",
      "10717 0\n",
      "10718 0\n",
      "10719 0\n",
      "10720 351\n",
      "10721 0\n",
      "10722 0\n",
      "10723 12\n",
      "10724 0\n",
      "10725 0\n",
      "10726 82\n",
      "10727 0\n",
      "10728 0\n",
      "10729 1607\n",
      "10730 600\n",
      "10731 319\n",
      "10732 176270\n",
      "10733 0\n",
      "10734 0\n",
      "10735 0\n",
      "10736 0\n",
      "10737 0\n",
      "10738 179\n",
      "10739 0\n",
      "10740 1134\n",
      "10741 410\n",
      "10742 4519\n",
      "10743 0\n",
      "10744 0\n",
      "10745 681\n",
      "10746 0\n",
      "10747 0\n",
      "10748 599\n",
      "10749 148\n",
      "10750 276\n",
      "10751 0\n",
      "10752 3238\n",
      "10753 0\n",
      "10754 0\n",
      "10755 600\n",
      "10756 0\n",
      "10757 38\n",
      "10758 231\n",
      "10759 1212\n",
      "10760 1042\n",
      "10761 0\n",
      "10762 0\n",
      "10763 0\n",
      "10764 90\n",
      "10765 0\n",
      "10766 0\n",
      "10767 21\n",
      "10768 0\n",
      "10769 79\n",
      "10770 0\n",
      "10771 0\n",
      "10772 297\n",
      "10773 0\n",
      "10774 4480\n",
      "10775 0\n",
      "10776 0\n",
      "10777 5580\n",
      "10778 0\n",
      "10779 123\n",
      "10780 183395\n",
      "10781 0\n",
      "10782 1\n",
      "10783 0\n",
      "10784 0\n",
      "10785 0\n",
      "10786 1265\n",
      "10787 0\n",
      "10788 0\n",
      "10789 5517\n",
      "10790 0\n",
      "10791 41\n",
      "10792 0\n",
      "10793 0\n",
      "10794 0\n",
      "10795 0\n",
      "10796 842\n",
      "10797 114\n",
      "10798 760\n",
      "10799 32\n",
      "10800 0\n",
      "10801 0\n",
      "10802 380\n",
      "10803 0\n",
      "10804 37\n",
      "10805 0\n",
      "10806 78140\n",
      "10807 1322\n",
      "10808 0\n",
      "10809 563\n",
      "10810 0\n",
      "10811 1195\n",
      "10812 0\n",
      "10813 320\n",
      "10814 0\n",
      "10815 0\n",
      "10816 191784\n",
      "10817 0\n",
      "10818 2572\n",
      "10819 1\n",
      "10820 83\n",
      "10821 0\n",
      "10822 325\n",
      "10823 231\n",
      "10824 154\n",
      "10825 3\n",
      "10826 0\n",
      "10827 567\n",
      "10828 0\n",
      "10829 586\n",
      "10830 0\n",
      "10831 0\n",
      "10832 94\n",
      "10833 0\n",
      "10834 958\n",
      "10835 639\n",
      "10836 0\n",
      "10837 0\n",
      "10838 0\n",
      "10839 4659\n",
      "10840 0\n",
      "10841 0\n",
      "10842 0\n",
      "10843 0\n",
      "10844 0\n",
      "10845 1546\n",
      "10846 0\n",
      "10847 500\n",
      "10848 60048\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "datasets_path = \"/data/WorkSpace/openbmb/dataset/medi2-data-jsonl/hard_negs/clean\"\n",
    "# for all the files\n",
    "files = os.listdir(datasets_path)\n",
    "files = [file for file in files if file.endswith(\".jsonl\")]\n",
    "\n",
    "# in_domain_datasets = [\n",
    "#     'cMedQA2',\n",
    "#     'dureader_retrieval',\n",
    "#     'marco_chinese',\n",
    "#     'mcpr-ecom',\n",
    "#     'mcpr-medical',\n",
    "#     'mcpr-video',\n",
    "#     'NCPPolicies',\n",
    "#     't2ranking'\n",
    "#     ]\n",
    "# # # files\n",
    "# files = ['clean'+file+'.jsonl' for file in in_domain_datasets]\n",
    "data = []\n",
    "\n",
    "for file_index,file in enumerate(files):\n",
    "    if file.startswith(\"train\"):\n",
    "        continue\n",
    "    if file.startswith(\"shenqing\"):\n",
    "        continue\n",
    "    if file.startswith(\"zhihu\"):\n",
    "        continue\n",
    "    line_count = sum(1 for line in open(os.path.join(datasets_path, file), 'r'))\n",
    "    print(file[:-6],line_count)\n",
    "    with jsonlines.open(os.path.join(datasets_path, file)) as reader:\n",
    "        i = 0\n",
    "        for obj in reader:\n",
    "            # obj[\"task_id\"] = file_index\n",
    "            if len(obj[\"neg\"]) < 6:\n",
    "                print(len(obj[\"neg\"]))\n",
    "            # obj[\"neg\"] = obj[\"neg\"][:6]\n",
    "            # print(len(obj[\"neg\"][:6])) n\n",
    "            data.append(obj)\n",
    "            i += 1\n",
    "            # if i > 500000:\n",
    "            #     break\n",
    "\n",
    "output_path = \"/data/WorkSpace/openbmb/dataset/medi2-data-jsonl/hard_negs/clean.jsonl\"\n",
    "with jsonlines.open(output_path, mode=\"w\") as writer:\n",
    "    writer.write_all(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "datasets_path = \"/data/WorkSpace/openbmb/dataset/medi2-data-jsonl/hard_negs/clean.jsonl\"\n",
    "\n",
    "# in_domain_datasets = [\n",
    "#     'cMedQA2',\n",
    "#     'dureader_retrieval',\n",
    "#     'marco_chinese',\n",
    "#     'mcpr-ecom',\n",
    "#     'mcpr-medical',\n",
    "#     'mcpr-video',\n",
    "#     'NCPPolicies',\n",
    "#     't2ranking'\n",
    "#     ]\n",
    "data = []\n",
    "with jsonlines.open(datasets_path ) as reader:\n",
    "    for obj in reader:\n",
    "        # obj[\"task_id\"] = file_index\n",
    "        if len(obj[\"neg\"]) < 6:\n",
    "            print(len(obj[\"neg\"]))\n",
    "        obj[\"neg\"] = obj[\"neg\"][:6]\n",
    "        # print(len(obj[\"neg\"][:6])) n\n",
    "        data.append(obj)\n",
    "        i += 1\n",
    "        # if i > 500000:\n",
    "        #     break\n",
    "\n",
    "output_path = \"/data/WorkSpace/openbmb/dataset/medi2-data-jsonl/hard_negs/clean_5negs.jsonl\"\n",
    "with jsonlines.open(output_path, mode=\"w\") as writer:\n",
    "    writer.write_all(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
